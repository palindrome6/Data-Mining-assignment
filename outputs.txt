[ 0.43420517  0.31739795  0.43868458  0.45862207  0.51529056  0.46696427
  0.37986335  0.7800343   0.48294267  0.60407943]    7
[ 0.49274129  0.46386674  0.59333009  0.57557791  0.32905021  0.54912996
  0.56727004  0.30177844  0.52201885  0.35499102]    2
[ 0.28009084  0.78818554  0.47067741  0.44973195  0.32747555  0.40737689
  0.40024111  0.38023525  0.48884508  0.3820433 ]    1
[ 0.85135418  0.41715217  0.66215533  0.65099818  0.61272746  0.73091632
  0.74497867  0.65799063  0.6458897   0.65332878]    0
[ 0.46129736  0.17454667  0.50583839  0.40305689  0.65856779  0.43951178
  0.48967198  0.50665468  0.47147274  0.56267929]    4
[ 0.31816441  0.85885835  0.52970797  0.53027815  0.40658662  0.47604904
  0.4160395   0.47534958  0.57814366  0.48000461]    1
[ 0.38478991  0.33064628  0.43845075  0.52592325  0.64222556  0.54629207
  0.43324286  0.58380264  0.55595607  0.60943729]    4
[ 0.38570711  0.43400705  0.4654654   0.51456457  0.60556698  0.56316751
  0.54269385  0.50536025  0.54432863  0.64212096]    9
[ 0.57837564  0.47383109  0.61908621  0.47101095  0.60667962  0.58267939
  0.61301416  0.48238513  0.57491034  0.57118493]    5
[ 0.57748449  0.52594018  0.56165999  0.54725969  0.741606    0.65015519
  0.60263729  0.78119504  0.66669464  0.78636491]    9
[ 0.76118314  0.25332314  0.52209938  0.57175845  0.40252897  0.58693337
  0.4407095   0.33879492  0.52428353  0.34673262]    0
[ 0.59279174  0.43064901  0.57587886  0.52661186  0.53962475  0.51131225
  0.57201129  0.42246699  0.54740489  0.48199213]    6

Process finished with exit code 0



cossim = 0
maxcos = 0

index1 = 0
index2 = 0
for n in training:
    numerator = 0
    denom1 = 0
    denom2 = 0
    for (i,k) in izip(test[0][0],n[0]):
        numerator += i*k
        denom1 += i*i
        denom2 += k*k
    if (denom1 != 0 and denom2 != 0):
        cossim =  numerator/(math.sqrt(denom1)*math.sqrt(denom2))
    if cossim >= maxcos:
        maxcos = cossim
        pred_number = serialised_to_decimal(training[index2][1])
        actual_number = test[0][1]

    index2 += 1
    if index2 == 100:
        index2 = 0
        break

print "Actual number: %d , Predicted number: %d" %(actual_number, pred_number)

-------------------------------------------------------------------------------------------------------------------------
test= 100
training = 10000
[[  8.   0.   0.   0.   0.   0.   0.   0.   0.   0.]
 [  0.  14.   0.   0.   0.   0.   0.   0.   0.   0.]
 [  0.   0.   8.   0.   0.   0.   0.   0.   0.   0.]
 [  0.   0.   0.  11.   0.   0.   0.   0.   0.   0.]
 [  0.   0.   0.   0.  13.   0.   0.   0.   0.   1.]
 [  0.   0.   0.   0.   0.   6.   0.   0.   0.   0.]
 [  0.   0.   0.   0.   0.   1.  10.   0.   0.   0.]
 [  0.   0.   0.   0.   0.   0.   0.  15.   0.   1.]
 [  0.   0.   0.   0.   0.   0.   0.   0.   2.   0.]
 [  0.   0.   0.   0.   1.   0.   0.   0.   0.   9.]]

 Precision of 0 : 1.000000
Recall of 0 : 1.000000
Precision of 1 : 1.000000
Recall of 1 : 1.000000
Precision of 2 : 1.000000
Recall of 2 : 1.000000
Precision of 3 : 1.000000
Recall of 3 : 1.000000
Precision of 4 : 0.928571
Recall of 4 : 0.928571
Precision of 5 : 1.000000
Recall of 5 : 0.857143
Precision of 6 : 0.909091
Recall of 6 : 1.000000
Precision of 7 : 0.937500
Recall of 7 : 1.000000
Precision of 8 : 1.000000
Recall of 8 : 1.000000
Precision of 9 : 0.900000
Recall of 9 : 0.818182
------------------------------------------------------------------------------------------------------------------------------------
test= 1000
training = 5000

[[  84.    0.    0.    0.    1.    2.    2.    0.    3.    0.]
 [   0.  126.    0.    1.    0.    1.    0.    1.    0.    0.]
 [   0.    0.  107.    0.    0.    0.    0.    2.    2.    0.]
 [   0.    0.    1.   94.    0.    4.    0.    0.    1.    0.]
 [   0.    0.    1.    0.   99.    0.    1.    0.    1.    4.]
 [   0.    0.    0.    4.    0.   72.    0.    1.    2.    0.]
 [   1.    0.    2.    2.    1.    2.   84.    0.    0.    0.]
 [   0.    0.    4.    2.    0.    1.    0.   91.    1.    3.]
 [   0.    0.    1.    3.    1.    5.    0.    0.   77.    4.]
 [   0.    0.    0.    1.    8.    0.    0.    4.    2.   83.]]

 Precision of 0 : 0.913043
Recall of 0 : 0.988235
Precision of 1 : 0.976744
Recall of 1 : 1.000000
Precision of 2 : 0.963964
Recall of 2 : 0.922414
Precision of 3 : 0.940000
Recall of 3 : 0.878505
Precision of 4 : 0.933962
Recall of 4 : 0.900000
Precision of 5 : 0.911392
Recall of 5 : 0.827586
Precision of 6 : 0.913043
Recall of 6 : 0.965517
Precision of 7 : 0.892157
Recall of 7 : 0.919192
Precision of 8 : 0.846154
Recall of 8 : 0.865169
Precision of 9 : 0.846939
Recall of 9 : 0.882979
[  92.  129.  111.  100.  106.   79.   92.  102.   91.   98.]
[  85.  126.  116.  107.  110.   87.   87.   99.   89.   94.]